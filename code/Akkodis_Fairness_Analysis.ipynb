{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m pip install --upgrade pip\n",
        "%pip install pandas matplotlib seaborn scikit-learn openpyxl tensorflow xgboost aif360\n",
        "%pip install \"aif360[Reductions, inFairness]\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tuNMyoGU1ExN",
        "outputId": "d5147e88-16d9-4b30-8bc3-48067a5f22d7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:No module named 'fairlearn': ExponentiatedGradientReduction will be unavailable. To install, run:\n",
            "pip install 'aif360[Reductions]'\n",
            "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
            "pip install 'aif360[Reductions]'\n",
            "WARNING:root:No module named 'inFairness': SenSeI and SenSR will be unavailable. To install, run:\n",
            "pip install 'aif360[inFairness]'\n",
            "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
            "pip install 'aif360[Reductions]'\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "from scipy.stats import chi2_contingency\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    accuracy_score, precision_score, recall_score, f1_score,\n",
        "    roc_auc_score, confusion_matrix\n",
        ")\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, BatchNormalization\n",
        "\n",
        "from aif360.datasets import BinaryLabelDataset\n",
        "from aif360.algorithms.inprocessing import AdversarialDebiasing\n",
        "\n",
        "random_seed = 15"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "PATH = 'C:/Users/aberti/Desktop/ProjectWork_AEQUITAS_AKKODIS/data/'\n",
        "df = (\n",
        "    pd.read_excel(PATH + 'Dataset_2.0_Akkodis.xlsx')\n",
        "      .rename(columns=lambda c: c.lstrip().title())\n",
        ")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nh5kHyh1ExO"
      },
      "source": [
        "### Clean Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fpIFJx6X1ExQ"
      },
      "outputs": [],
      "source": [
        "unuseful_columns = [\n",
        "    'ID', 'TAG', 'Year of insertion', 'Year of Recruitment', 'Recruitment Request', \n",
        "    'Assumption Headquarters', 'event_type__val', 'linked_search__key', 'Job Description', \n",
        "    'Candidate Profile', 'Akkodis headquarters', 'Standing/Position', 'Unnamed: 0', \n",
        "    'Residence', 'Last Role', 'Study Area.1', 'Years Experience.1']\n",
        "df = df.drop(columns=unuseful_columns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMUqnCTP1ExS",
        "outputId": "f33ab5da-3da3-4b40-c926-bb00e99d914d"
      },
      "outputs": [],
      "source": [
        "for feature in df.columns:\n",
        "    print(f'Feature: {feature} -- {list(df[feature].unique())}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmg_n5ol1ExS"
      },
      "source": [
        "### Handle the NANs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGr8pjDc1ExT",
        "outputId": "50b0cb55-a0a6-474b-802c-6e000aced0ad"
      },
      "outputs": [],
      "source": [
        "print(df.columns[df.isnull().any()].tolist())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5xUD3IuZ1ExT"
      },
      "outputs": [],
      "source": [
        "df['Citizenship'] = df['Citizenship'].fillna('Not Specified')\n",
        "\n",
        "df['Protected category'] = df['Protected category'].fillna('Not a protected category')\n",
        "df['Protected Category'] = df['Protected Category'].replace('Article 18', 'Yes')\n",
        "df['Protected Category'] = df['Protected Category'].replace('Article 1', 'Yes')\n",
        "\n",
        "df['Study area'] = df['Study area'].fillna('Not Specified')\n",
        "df['Sector'] = df['Sector'].fillna('Unemployed')\n",
        "df['Job Family Hiring'] = df['Job Family Hiring'].fillna('Not Specified')\n",
        "df['Job Title Hiring'] = df['Job Title Hiring'].fillna('Not Specified')\n",
        "df['vent_feedback'] = df['ent_feedback'].fillna('Not Specified')\n",
        "df['verall'] = df['verall'].fillna('Not Specified')\n",
        "df['Minimum Ral'] = df['Minimum Ral'].fillna('Not Specified')\n",
        "df['Ral Maximum'] = df['Ral Maximum'].fillna('Not Specified')\n",
        "df['Study Level'] = df['Study Level'].fillna('Not Specified')\n",
        "df['Current Ral'] = df['Current Ral'].fillna('Not Specified')\n",
        "df['Expected Ral'] = df['Expected Ral'].fillna('Not Specified')\n",
        "df['Technical Skills'] = df['Technical Skills'].fillna(df['Technical Skills'].mean())\n",
        "df['Comunication'] = df['Comunication'].fillna(df['Comunication'].mean())\n",
        "df['Maturity'] = df['Maturity'].fillna(df['Maturity'].mean())\n",
        "df['Dynamism'] = df['Dynamism'].fillna(df['Dynamism'].mean())\n",
        "df['Mobility'] = df['Mobility'].fillna(df['Mobility'].mean())\n",
        "df['English'] = df['English'].fillna(df['English'].mean())\n",
        "\n",
        "print(f'There are {df.isnull().sum().sum()} NANs')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohSRbTbT1ExU"
      },
      "source": [
        "### Features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "citizenship_mapping = {\n",
        "    'Pakistani': 'Non-European',\n",
        "    'Italian': 'European',\n",
        "    'Not Specified': 'Non-European',\n",
        "    'Moroccan': 'Non-European',\n",
        "    'Iranian': 'Non-European',\n",
        "    'Albanian': 'European',\n",
        "    'Indiana': 'Non-European',\n",
        "    'Colombian': 'Non-European',\n",
        "    'Ethiopian': 'Non-European',\n",
        "    'Romanian': 'European',\n",
        "    'Vltava': 'European',\n",
        "    'Lebanese': 'Non-European',\n",
        "    'Spanish': 'European',\n",
        "    'Egyptian': 'Non-European',\n",
        "    'Russian': 'European',\n",
        "    'Tunisian': 'Non-European',\n",
        "    'Turkish': 'European',\n",
        "    'Chinese': 'Non-European',\n",
        "    'Uzbek': 'Non-European',\n",
        "    'Brazilian': 'Non-European',\n",
        "    'Cameroonian': 'Non-European',\n",
        "    'Sudanese': 'Non-European',\n",
        "    'Algerian': 'Non-European',\n",
        "    'Croatian': 'European',\n",
        "    'Polish': 'European',\n",
        "    'Indonesian': 'Non-European',\n",
        "    'San Marino': 'European',\n",
        "    'Argentina': 'Non-European',\n",
        "    'Azerbaijan': 'Non-European',\n",
        "    'Portuguese': 'European',\n",
        "    'Serbian': 'European',\n",
        "    'French': 'European',\n",
        "    'Swiss': 'European',\n",
        "    'German': 'European',\n",
        "    'Peruvian': 'Non-European',\n",
        "    'British': 'European',\n",
        "    'Venezuelan': 'Non-European',\n",
        "    'Rwandan': 'Non-European',\n",
        "    'Costa Rican': 'Non-European',\n",
        "    'South Korean': 'Non-European',\n",
        "    'Ukraine': 'European',\n",
        "    'Macedonian': 'European',\n",
        "    'Nigerian': 'Non-European',\n",
        "    'American': 'Non-European',\n",
        "    'Kenyan': 'Non-European',\n",
        "    'Emirati': 'Non-European',\n",
        "    'Ecuadorian': 'Non-European',\n",
        "    'Ivorian': 'Non-European',\n",
        "    'Mexican': 'Non-European',\n",
        "    'Chilean': 'Non-European',\n",
        "    'Japanese': 'Non-European',\n",
        "    'Syrian': 'Non-European',\n",
        "    'Bangladeshis': 'Non-European',\n",
        "    'Greek': 'European',\n",
        "    'Israeli': 'Non-European',\n",
        "    'Omani': 'Non-European',\n",
        "    'South African': 'Non-European',\n",
        "    'Bolivian': 'Non-European',\n",
        "    'Filipina': 'Non-European',\n",
        "    'Sinhalese': 'Non-European',\n",
        "    'Palestinian (Palestinian Territories)': 'Non-European',\n",
        "    'Afghan': 'Non-European',\n",
        "    'Jordan': 'Non-European',\n",
        "    'Cuban': 'Non-European',\n",
        "    'Vietnamese': 'Non-European',\n",
        "    'Latvian': 'European',\n",
        "    'Libyan': 'Non-European',\n",
        "    'Bulgarian': 'European',\n",
        "    'Togolese': 'Non-European',\n",
        "    'Kazakh': 'Non-European',\n",
        "    'Austrian': 'European',\n",
        "    'Belarusian': 'European',\n",
        "    'Saudi': 'Non-European',\n",
        "    'Bosnian': 'European',\n",
        "    'Kyrgyz': 'Non-European',\n",
        "    'Tajik': 'Non-European',\n",
        "    'Dutch': 'European',\n",
        "    'Qatari': 'Non-European',\n",
        "    'Georgian': 'European',\n",
        "    'Canadian': 'Non-European',\n",
        "    'Australian': 'Non-European',\n",
        "    'Salvadoran': 'Non-European',\n",
        "    'Congolese': 'Non-European',\n",
        "    'Guatemalan': 'Non-European',\n",
        "    'Hungarian': 'European',\n",
        "    'Tanzanian': 'Non-European',\n",
        "    'Gabonese': 'Non-European',\n",
        "    'Angolan': 'Non-European',\n",
        "    'Maltese': 'European'\n",
        "}\n",
        "\n",
        "study_area_mapping = {\n",
        "    'Automation/Mechatronics Engineering': 'Engineering',\n",
        "    'computer engineering': 'Engineering',\n",
        "    'chemical engineering': 'Engineering',\n",
        "    'Legal': 'Law',\n",
        "    'Mechanical engineering': 'Engineering',\n",
        "    'Telecommunications Engineering': 'Engineering',\n",
        "    'Economic - Statistics': 'Economic',\n",
        "    'Psychology': 'Scientific Field',\n",
        "    'Materials Science and Engineering': 'Engineering',\n",
        "    'Other scientific subjects': 'Scientific Field',\n",
        "    'Biomedical Engineering': 'Engineering',\n",
        "    'electronic Engineering': 'Engineering',\n",
        "    'Information Engineering': 'Engineering',\n",
        "    'Aeronautical/Aerospace/Astronautics Engineering': 'Engineering',\n",
        "    'Energy and Nuclear Engineering': 'Engineering',\n",
        "    'Informatics': 'Informatics',\n",
        "    'Management Engineering': 'Engineering',\n",
        "    'Automotive Engineering': 'Engineering',\n",
        "    'industrial engineering': 'Engineering',\n",
        "    'Other': 'Other',\n",
        "    'Surveyor': 'NO COLLEGE',\n",
        "    'Civil/Civil and Environmental Engineering': 'Engineering',\n",
        "    'Electrical Engineering': 'Engineering',\n",
        "    'Scientific maturity': 'NO COLLEGE',\n",
        "    'Chemist - Pharmaceutical': 'Medical Field',\n",
        "    'Political-Social': 'Other Humanities Subjects',\n",
        "    'Other humanities subjects': 'Other Humanities Subjects',\n",
        "    'Geo-Biological': 'Scientific Field',\n",
        "    'Linguistics': 'Linguistics',\n",
        "    'Agriculture and veterinary': 'Scientific Field',\n",
        "    'Literary': 'Other Humanities Subjects',\n",
        "    'Humanistic high school diploma': 'NO COLLEGE',\n",
        "    'Accounting': 'NO COLLEGE',\n",
        "    'Communication Sciences': 'Other Humanities Subjects',\n",
        "    'Safety Engineering': 'Engineering',\n",
        "    'Architecture': 'Scientific Field',\n",
        "    'Mathematics': 'Scientific Field',\n",
        "    'construction Engineering': 'Engineering',\n",
        "    'Petroleum Engineering': 'Engineering',\n",
        "    'Naval Engineering': 'Engineering',\n",
        "    'Artistic': 'NO COLLEGE',\n",
        "    'Not Specified': 'Other',\n",
        "    'Mathematical-physical modeling for engineering': 'Engineering',\n",
        "    'Engineering for the environment and the territory': 'Engineering',\n",
        "    'Medical': 'Medical Field',\n",
        "    'Defense and Security': 'Other',\n",
        "    'Physical education': 'Other',\n",
        "    'Statistics': 'Scientific Field',\n",
        "    'Educational/training sciences': 'Other Humanities Subjects'\n",
        "\n",
        "}\n",
        "\n",
        "age_mapping = {\n",
        "    '< 20 years': 'Young',\n",
        "    '20 - 25 years': 'Young',\n",
        "    '26 - 30 years': 'Young',\n",
        "    '31 - 35 years': 'Young',\n",
        "    '36 - 40 years': 'Senior',\n",
        "    '40 - 45 years': 'Senior',\n",
        "    '> 45 years': 'Senior'\n",
        "}\n",
        "\n",
        "df['Citizenship'] = df['Citizenship'].replace(citizenship_mapping)\n",
        "df['Age Range'] = df['Age Range'].replace(age_mapping)\n",
        "df['Study area'] = df['Study area'].replace(study_area_mapping)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlOnBSVF1ExV"
      },
      "source": [
        "### Target Column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N6iNmw50rLwG",
        "outputId": "5af7fd8b-272e-44b2-8967-adfb2d9f24fe"
      },
      "outputs": [],
      "source": [
        "statuses_to_remove = ['First contact', 'Imported']\n",
        "df = df[~df['Candidate State'].isin(statuses_to_remove)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRjVe10r1ExV",
        "outputId": "88790b0c-536a-41d4-bbb2-1341787a8e9d"
      },
      "outputs": [],
      "source": [
        "df['STATUS'] = np.where(\n",
        "    (df[' Candidate State'] == 'Hired') | \n",
        "    (df[' Candidate State'] == 'Economic proposal') | \n",
        "    (df[' event_feedback'] == 'OK (live)') | \n",
        "    (df[' event_feedback'] == 'OK (waiting for departure)') | \n",
        "    (df[' event_feedback'] == 'OK (hired)') | \n",
        "    (df[' Candidate State'] == 'QM'), 1, 0)\n",
        "# 1 means the candidate is considered valid (even if still not hired), 0 the candidate is not considered valid for some reason\n",
        "\n",
        "lookup = 'STATUS'\n",
        "distrib = Counter(df[lookup])\n",
        "distrib_df = pd.DataFrame(distrib.items(), columns=[lookup, 'Count'])\n",
        "distrib_df = distrib_df.sort_values(by='Count', ascending=False)\n",
        "distrib_df.head(20).plot(x=lookup, y='Count', kind='bar', legend=False)\n",
        "plt.title(lookup)\n",
        "plt.xticks(rotation=45)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GkzsY6s1ExW"
      },
      "source": [
        "### Categorical columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gOBlkj5x1ExW"
      },
      "outputs": [],
      "source": [
        "categorical_columns = [' Age Range', ' Citizenship', ' Sex',\n",
        "       ' Protected category', ' Study area', ' Study Title',\n",
        "       ' Years Experience', ' Sector', ' Job Family Hiring',\n",
        "       ' Job Title Hiring', ' Overall',\n",
        "       ' Minimum Ral', ' Ral Maximum', ' Study Level',\n",
        "       'Current Ral', 'Expected Ral']\n",
        "\n",
        "encoding_mappings = {}\n",
        "for column in categorical_columns:\n",
        "    encoder = LabelEncoder()\n",
        "    df[f'{column}_encoded'] = encoder.fit_transform(df[column].astype(str))\n",
        "    encoding_mappings[column] = dict(zip(encoder.classes_, encoder.transform(encoder.classes_)))\n",
        "\n",
        "df = df.drop(columns=categorical_columns + ['Candidate State', 'Event_Feedback'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIYO8Uhi1ExW"
      },
      "source": [
        "### Visualize Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Citizenship"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pzZVAvmW1ExW"
      },
      "outputs": [],
      "source": [
        "lookup = 'Citizenship'\n",
        "mapping = {v: k for k, v in encoding_mappings[lookup].items()}\n",
        "\n",
        "distrib = Counter(df[lookup + \"_encoded\"])\n",
        "distrib_df = pd.DataFrame(distrib.items(), columns=[lookup + \"_encoded\", 'Count'])\n",
        "distrib_df = distrib_df.sort_values(by='Count', ascending=False)\n",
        "distrib_df.head(20).plot(x=lookup + \"_encoded\", y='Count', kind='bar', legend=False)\n",
        "plt.title(lookup)\n",
        "plt.xticks(rotation=45)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Age"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "lookout = 'Age Range'\n",
        "mapping = {v: k for k, v in encoding_mappings[lookout].items()}\n",
        "\n",
        "distrib = Counter(df[lookup + \"_encoded\"])\n",
        "distrib_df = pd.DataFrame(distrib.items(), columns=[lookup + \"_encoded\", 'Count'])\n",
        "distrib_df = distrib_df.sort_values(by='Count', ascending=False)\n",
        "distrib_df.head(20).plot(x=lookup + \"_encoded\", y='Count', kind='bar', legend=False)\n",
        "plt.title(lookup)\n",
        "plt.xticks(rotation=45)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Gender"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "lookout = 'Sex'\n",
        "mapping = {v: k for k, v in encoding_mappings[lookout].items()}\n",
        "\n",
        "distrib = Counter(df[lookup + \"_encoded\"])\n",
        "distrib_df = pd.DataFrame(distrib.items(), columns=[lookup + \"_encoded\", 'Count'])\n",
        "distrib_df = distrib_df.sort_values(by='Count', ascending=False)\n",
        "distrib_df.head(20).plot(x=lookup + \"_encoded\", y='Count', kind='bar', legend=False)\n",
        "plt.title(lookup)\n",
        "plt.xticks(rotation=45)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Protected Category"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "lookout = 'Protected category'\n",
        "mapping = {v: k for k, v in encoding_mappings[lookout].items()}\n",
        "\n",
        "distrib = Counter(df[lookup + \"_encoded\"])\n",
        "distrib_df = pd.DataFrame(distrib.items(), columns=[lookup + \"_encoded\", 'Count'])\n",
        "distrib_df = distrib_df.sort_values(by='Count', ascending=False)\n",
        "distrib_df.head(20).plot(x=lookup + \"_encoded\", y='Count', kind='bar', legend=False)\n",
        "plt.title(lookup)\n",
        "plt.xticks(rotation=45)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Correlation Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sns.heatmap(df.corr(), annot=True, cmap='coolwarm', center=0, linewidths=.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualize Percentage of Hired inside each class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sensitive = ['Sex_encoded', 'Age Range_encoded', 'Citizenship_encoded', 'Protected Category_encoded']\n",
        "for feature in sensitive:\n",
        "    percentage = df.groupby(feature)['STATUS'].mean().mul(100).round(2)\n",
        "    for category, perc in percentage.items():\n",
        "        print(f\"Percentage of elements where {feature} is {category} and STATUS is HIRED: {percentage:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NM7TxgLU1ExW"
      },
      "source": [
        "## **Task 2 - Algorithms**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8PH7esVa1ExW"
      },
      "outputs": [],
      "source": [
        "# Shuffle the dataset\n",
        "df = shuffle(df, random_state=random_seed)\n",
        "\n",
        "# Split in X and y\n",
        "X = df.drop(columns=['STATUS'])\n",
        "y = df['STATUS']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_seed)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXTBN9yJ1ExW"
      },
      "source": [
        "##### **2.1 Machine Learning models**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7neYICfm1ExW"
      },
      "outputs": [],
      "source": [
        "models = {\n",
        "    'Linear Regression': LinearRegression(),\n",
        "    'Decision Tree': DecisionTreeClassifier(),\n",
        "    'Naive Bayes': GaussianNB(),\n",
        "    'XGBoost': XGBClassifier(),\n",
        "    'KNN': KNeighborsClassifier(),\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "bSyQkZB91ExX",
        "outputId": "166c5665-77b9-4e4b-d2b7-e20eef41a9d7"
      },
      "outputs": [],
      "source": [
        "metrics = []\n",
        "predictions = {}\n",
        "\n",
        "# Fit models and evaluate\n",
        "for name, model in models.items():\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    if name in ['Linear Regression', 'XGBoost']:\n",
        "        y_pred = (y_pred > 0.5).astype(int)\n",
        "\n",
        "    # Store predictions\n",
        "    predictions[name] = y_pred\n",
        "\n",
        "    accuracy = round(accuracy_score(y_test, y_pred), 3)\n",
        "    precision = round(precision_score(y_test, y_pred), 3)\n",
        "    recall = round(recall_score(y_test, y_pred), 3)\n",
        "    f1 = round(f1_score(y_test, y_pred), 3)\n",
        "    roc_auc = round(roc_auc_score(y_test, y_pred), 3)\n",
        "\n",
        "    # Append metrics to the DataFrame\n",
        "    metrics.append({\n",
        "        'Model': name,\n",
        "        'Accuracy': accuracy,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1-score': f1,\n",
        "        'ROC AUC': roc_auc\n",
        "    })\n",
        "\n",
        "metrics = pd.DataFrame(metrics)\n",
        "metrics.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G0uu0EVz1ExY"
      },
      "outputs": [],
      "source": [
        "predictions_df = pd.DataFrame({\n",
        "    'Linear Regression' : predictions['Linear Regression'],\n",
        "    'Decision Tree' : predictions['Decision Tree'],\n",
        "    'Naive Bayes' : predictions['Naive Bayes'],\n",
        "    'XGBoost' : predictions['XGBoost'],\n",
        "    'kNN' : predictions['KNN']\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrphgMCM1ExY"
      },
      "source": [
        "##### **2.2 Neural Network**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UNe1dyFl1ExY"
      },
      "outputs": [],
      "source": [
        "def create_model():\n",
        "    model = Sequential()\n",
        "    model.add(Dense(128, input_dim=22, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# List to hold the models\n",
        "neural_models = []\n",
        "\n",
        "# Create and compile 7 models with different seeds\n",
        "for seed in range(85,92):\n",
        "    np.random.seed(seed)\n",
        "    tf.random.set_seed(seed)\n",
        "    model = create_model()\n",
        "    neural_models.append(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICPmn4A41ExZ",
        "outputId": "fe4e6e36-426c-4036-efcb-b1d29727fb30"
      },
      "outputs": [],
      "source": [
        "# Fit the models\n",
        "histories = []\n",
        "for i, model in enumerate(neural_models):\n",
        "    print(f\"Fitting model {i+1}...\")\n",
        "    history = model.fit(X_train, y_train, epochs=15, batch_size=64, validation_split=0.2)\n",
        "    histories.append(history)\n",
        "    print(f\"Model {i+1} fitted.\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 947
        },
        "id": "e7lXYUNG1ExZ",
        "outputId": "cd959bfd-bfde-4a5c-e124-0d7ca82c4841"
      },
      "outputs": [],
      "source": [
        "# Check training procedure\n",
        "plt.plot(histories[0].history['accuracy'])\n",
        "plt.plot(histories[0].history['val_accuracy'])\n",
        "plt.title('Model 1 accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(histories[0].history['loss'])\n",
        "plt.plot(histories[0].history['val_loss'])\n",
        "plt.title('Model 1 loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A6_39rko1ExZ",
        "outputId": "a0343c1f-34f5-4e32-8e4b-b993e36aec4d"
      },
      "outputs": [],
      "source": [
        "neural_predictions = []\n",
        "\n",
        "for i, model in enumerate(neural_models):\n",
        "    print(f\"Predicting with model {i+1}...\")\n",
        "    y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
        "    neural_predictions.append(y_pred)\n",
        "    print(f\"Predictions from model {i+1} stored.\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "id": "QS9EFYsf1Exa",
        "outputId": "a7ab4f1f-054e-46da-e4b2-5e7e7c23d88a"
      },
      "outputs": [],
      "source": [
        "nn_metrics = []\n",
        "\n",
        "for i, y_pred in enumerate(neural_predictions):\n",
        "    accuracy = round(accuracy_score(y_test, y_pred), 3)\n",
        "    precision = round(precision_score(y_test, y_pred), 3)\n",
        "    recall = round(recall_score(y_test, y_pred), 3)\n",
        "    f1 = round(f1_score(y_test, y_pred), 3)\n",
        "    roc_auc = round(roc_auc_score(y_test, y_pred), 3)\n",
        "\n",
        "    nn_metrics.append({\n",
        "        \"Model\": f\"Neural Network {i+1}\",\n",
        "        \"Accuracy\": accuracy,\n",
        "        \"Precision\": precision,\n",
        "        \"Recall\": recall,\n",
        "        \"F1-score\": f1,\n",
        "        \"ROC AUC\": roc_auc\n",
        "    })\n",
        "\n",
        "# Display the 7 models performances\n",
        "nn_metrics = pd.DataFrame(nn_metrics)\n",
        "nn_metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "id": "isMBPxkG1Exa",
        "outputId": "50de377a-c023-49ee-d5b1-bb1ebf96c8c4"
      },
      "outputs": [],
      "source": [
        "combined_metrics = pd.concat([metrics, nn_metrics], ignore_index=True)\n",
        "combined_metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7x-FX6Ab1Exa"
      },
      "outputs": [],
      "source": [
        "# Add the NN to the models and to the predicitons\n",
        "for i, model in enumerate(neural_models):\n",
        "    models[f\"Neural Network {i+1}\"] = model\n",
        "\n",
        "for i, prediction_list in enumerate(neural_predictions):\n",
        "    predictions_df[f'Neural Network {i+1}'] = prediction_list.flatten()\n",
        "    predictions[f'Neural Network {i+1}'] = prediction_list.flatten()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GybD2fNN1Exa"
      },
      "source": [
        "## **Task 3 - Fairness Metrics**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Ws-DQHm1Exa"
      },
      "source": [
        "#### **3.1 Demographic Parity**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qCdj5tff1Exb"
      },
      "outputs": [],
      "source": [
        "# Columns groups of interest\n",
        "sensitive_features = [' Sex_encoded', ' Age Range_encoded', ' Citizenship_encoded', ' Protected category_encoded']\n",
        "non_sensitive_features = ['Technical Skills', 'Comunication', 'Maturity', 'Dynamism', 'Mobility',\n",
        "       'English', ' Study area_encoded', ' Study Title_encoded', ' Years Experience_encoded', ' Sector_encoded', ' Job Family Hiring_encoded',\n",
        "       ' Job Title Hiring_encoded', ' Overall_encoded', ' Years Experience.1_encoded',' Minimum Ral_encoded', ' Ral Maximum_encoded',\n",
        "       ' Study Level_encoded', 'Current Ral_encoded', 'Expected Ral_encoded']\n",
        "\n",
        "models_list = [model for model in models]\n",
        "\n",
        "# Tresholds\n",
        "tolerance = 0.15\n",
        "significance_level = 0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QzubVOQ61Exb"
      },
      "outputs": [],
      "source": [
        "def calculate_demographic_parity(predictions, sensitive_attribute, name, significance_level, tolerance, activate_check=False):\n",
        "\n",
        "    df = pd.DataFrame({\n",
        "        'predictions': predictions,\n",
        "        'sensitive_attribute': sensitive_attribute\n",
        "    })\n",
        "\n",
        "    # Proportion of positive predictions for each group   \n",
        "    positive_proportions = df.groupby('sensitive_attribute')['predictions'].mean()\n",
        "    num_class = positive_proportions.shape[0]\n",
        "    min_proportion = positive_proportions.min()\n",
        "    max_proportion = positive_proportions.max()\n",
        "    percentage_difference = (max_proportion - min_proportion)\n",
        "\n",
        "    # Case for binary sensitive attribute\n",
        "    if num_class == 2:\n",
        "        \n",
        "        if activate_check == True:\n",
        "            print(\"===\")\n",
        "            print(name)\n",
        "            print(positive_proportions)\n",
        "\n",
        "        if percentage_difference <= tolerance:\n",
        "            return 'T'\n",
        "        else:\n",
        "            return False\n",
        "\n",
        "    # Case for multiclass sensitive attribute\n",
        "    if num_class > 2:\n",
        "        contingency_table = pd.crosstab(df['predictions'], df['sensitive_attribute'])\n",
        "        chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
        "\n",
        "        if activate_check == True:\n",
        "            print(\"===\")\n",
        "            print(name)\n",
        "            print(positive_proportions)\n",
        "            if (expected < 5).any():\n",
        "                print(f\"Sparse contigency for {name}\")\n",
        "                \n",
        "        if p > significance_level:\n",
        "            return 'T'\n",
        "        else:\n",
        "            return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 862
        },
        "id": "dYqVcPet1Exb",
        "outputId": "6422f8a3-7d22-4ab2-d8b8-867596fc79dc"
      },
      "outputs": [],
      "source": [
        "# Models behaviours over sensitive features\n",
        "table = []\n",
        "\n",
        "for model in models:\n",
        "     temp = []\n",
        "     for i in range(len(sensitive_features)):\n",
        "        Boolean_Output = calculate_demographic_parity(predictions[model], X_test[sensitive_features[i]], sensitive_features[i], significance_level, tolerance, activate_check=True)\n",
        "        temp.append(Boolean_Output)\n",
        "     table.append(temp)\n",
        "\n",
        "sf_df = pd.DataFrame(table, index = models_list, columns=sensitive_features)\n",
        "sf_df.head(len(models_list))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJ1zcOEM1Exb"
      },
      "source": [
        "#### **3.2 Equalized odds**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wXbOhlKv1Exb"
      },
      "outputs": [],
      "source": [
        "def calculate_equalized_odds(predictions, true_labels, sensitive_attribute, name, tolerance, activate_check=False):\n",
        "    df = pd.DataFrame({\n",
        "        'predictions': predictions,\n",
        "        'true_labels': true_labels,\n",
        "        'sensitive_attribute': sensitive_attribute\n",
        "    })\n",
        "\n",
        "    # Calculate TPR and FPR for each group\n",
        "    groups = df['sensitive_attribute'].unique()\n",
        "    metrics = {}\n",
        "    for group in groups:\n",
        "        group_df = df[df['sensitive_attribute'] == group]\n",
        "        cm = confusion_matrix(group_df['true_labels'], group_df['predictions'], labels=[0, 1])\n",
        "        tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "        tpr = tp / (tp + fn) if tp + fn != 0 else 0\n",
        "        fpr = fp / (fp + tn) if fp + tn != 0 else 0\n",
        "        metrics[group] = {'TPR': tpr, 'FPR': fpr}\n",
        "\n",
        "    # Check if TPR and FPR are within the tolerance\n",
        "    tprs = [metrics[group]['TPR'] for group in groups]\n",
        "    fprs = [metrics[group]['FPR'] for group in groups]\n",
        "\n",
        "    max_tpr_diff = max(tprs) - min(tprs)\n",
        "    max_fpr_diff = max(fprs) - min(fprs)\n",
        "\n",
        "    if activate_check == True:\n",
        "        print(\"===\")\n",
        "        print(name)\n",
        "        print(max_fpr_diff)\n",
        "        print(max_tpr_diff)\n",
        "\n",
        "    tpr_within_tolerance = max_tpr_diff <= tolerance*2\n",
        "    fpr_within_tolerance = max_fpr_diff <= tolerance*2\n",
        "\n",
        "    if tpr_within_tolerance and fpr_within_tolerance:\n",
        "        return 'T'\n",
        "    else:\n",
        "        return False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "id": "9KSoLzk21Exb",
        "outputId": "6f420612-90e8-4537-f6fb-43add15ddac2"
      },
      "outputs": [],
      "source": [
        "# Equalized odds\n",
        "table = []\n",
        "\n",
        "for model in models:\n",
        "    temp = []\n",
        "    for i in range(len(sensitive_features)):\n",
        "        Boolean_Output = calculate_equalized_odds(predictions[model], y_test, X_test[sensitive_features[i]], sensitive_features[i], tolerance, activate_check=False)\n",
        "        temp.append(Boolean_Output)\n",
        "    table.append(temp)\n",
        "\n",
        "# DataFrame\n",
        "equalized_df = pd.DataFrame(table, index = models_list, columns=sensitive_features)\n",
        "equalized_df.head(len(models_list))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
