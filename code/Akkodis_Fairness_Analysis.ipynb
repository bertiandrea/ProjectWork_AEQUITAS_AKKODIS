{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!python -m pip install --upgrade pip\n",
        "%pip install pandas matplotlib seaborn scikit-learn openpyxl tensorflow xgboost aif360\n",
        "%pip install \"aif360[Reductions, inFairness]\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tuNMyoGU1ExN",
        "outputId": "d5147e88-16d9-4b30-8bc3-48067a5f22d7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:root:No module named 'fairlearn': ExponentiatedGradientReduction will be unavailable. To install, run:\n",
            "pip install 'aif360[Reductions]'\n",
            "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
            "pip install 'aif360[Reductions]'\n",
            "WARNING:root:No module named 'inFairness': SenSeI and SenSR will be unavailable. To install, run:\n",
            "pip install 'aif360[inFairness]'\n",
            "WARNING:root:No module named 'fairlearn': GridSearchReduction will be unavailable. To install, run:\n",
            "pip install 'aif360[Reductions]'\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "from scipy.stats import chi2_contingency\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential # type: ignore\n",
        "from tensorflow.keras.layers import Dense, BatchNormalization # type: ignore\n",
        "\n",
        "from aif360.datasets import BinaryLabelDataset, StandardDataset\n",
        "from aif360.algorithms.preprocessing import LFR\n",
        "from fairlearn.preprocessing import CorrelationRemover\n",
        "from aif360.algorithms.inprocessing import GerryFairClassifier, PrejudiceRemover, MetaFairClassifier\n",
        "from aif360.algorithms.postprocessing import EqOddsPostprocessing, RejectOptionClassification\n",
        "\n",
        "from fairlearn.metrics import MetricFrame\n",
        "from fairlearn.metrics import demographic_parity_difference, equalized_odds_difference, selection_rate, false_positive_rate, false_negative_rate, count\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
        "\n",
        "random_seed = 15"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "PATH = 'C:/Users/aberti/Desktop/ProjectWork_AEQUITAS_AKKODIS/data/'\n",
        "df = (\n",
        "    pd.read_excel(PATH + 'Dataset_2.0_Akkodis.xlsx')\n",
        "      .rename(columns=lambda c: c.lstrip().title())\n",
        ")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nh5kHyh1ExO"
      },
      "source": [
        "### Clean Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = df.drop_duplicates(subset='Id', keep='last')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fpIFJx6X1ExQ"
      },
      "outputs": [],
      "source": [
        "unuseful_columns = [\n",
        "    'ID', 'TAG', 'Year of insertion', 'Year of Recruitment', 'Recruitment Request', \n",
        "    'Assumption Headquarters', 'event_type__val', 'linked_search__key', 'Job Description', \n",
        "    'Candidate Profile', 'Akkodis headquarters', 'Standing/Position', 'Unnamed: 0', \n",
        "    'Residence', 'Last Role', 'Study Area.1', 'Years Experience.1']\n",
        "df = df.drop(columns=unuseful_columns)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "THRESHOLD = 0.4\n",
        "unuseful_columns = []\n",
        "for col in df.columns:\n",
        "  null_count = df[col].isna().sum() / df.shape[0]\n",
        "  if null_count > THRESHOLD:\n",
        "    unuseful_columns.append(col)\n",
        "    print(f'DROPPED <Column: {col}> NULL count: {null_count*100:.2f}%')\n",
        "  else:\n",
        "    print(f'<Column: {col}> NULL count: {null_count*100:.2f}%')\n",
        "  \n",
        "df = df.drop(columns=unuseful_columns)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pMUqnCTP1ExS",
        "outputId": "f33ab5da-3da3-4b40-c926-bb00e99d914d"
      },
      "outputs": [],
      "source": [
        "for feature in df.columns:\n",
        "    print(f'Feature: {feature} -- {list(df[feature].unique())}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rows_mappings = {\n",
        "    'Protected Category': {\n",
        "        'Article 18': 'Yes',\n",
        "        'Article 1': 'Yes'\n",
        "    }\n",
        "}\n",
        "for col, mapping in rows_mappings.items():\n",
        "    df[col] = df[col].replace(mapping)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Remove rows with 'Candidate State' as 'First contact' or 'Imported'\n",
        "# These statuses are not relevant for the analysis\n",
        "rows_to_remove = {\n",
        "    'Candidate State': ['First contact', 'Imported']\n",
        "}\n",
        "\n",
        "for col, remove_list in rows_to_remove.items():\n",
        "    df = df[~df[col].isin(remove_list)]\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kmg_n5ol1ExS"
      },
      "source": [
        "### Handle the NANs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGr8pjDc1ExT",
        "outputId": "50b0cb55-a0a6-474b-802c-6e000aced0ad"
      },
      "outputs": [],
      "source": [
        "print(f'Columns that contain NaN values:\\n {df.columns[df.isnull().any()].tolist()}')\n",
        "\n",
        "for col in df.columns[df.isnull().any()].tolist():\n",
        "  print(f'{col} values: {df[col].unique()} \\n') # Analyze each NaN containing feature first to determine the default fill value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5xUD3IuZ1ExT"
      },
      "outputs": [],
      "source": [
        "fill_values = {\n",
        "    'Citizenship': 'Not Specified',\n",
        "    'Protected category': 'Not a protected category',\n",
        "    'Study area': 'Not Specified',\n",
        "    'Sector': 'Unemployed',\n",
        "    'Job Family Hiring': 'Not Specified',\n",
        "    'Job Title Hiring': 'Not Specified',\n",
        "    'vent_feedback': 'Not Specified',\n",
        "    'verall': 'Not Specified',\n",
        "    'Minimum Ral': 'Not Specified',\n",
        "    'Ral Maximum': 'Not Specified',\n",
        "    'Study Level': 'Not Specified',\n",
        "    'Current Ral': 'Not Specified',\n",
        "    'Expected Ral': 'Not Specified',\n",
        "    'Technical Skills': df['Technical Skills'].mean(),\n",
        "    'Comunication': df['Comunication'].mean(),\n",
        "    'Maturity': df['Maturity'].mean(),\n",
        "    'Dynamism': df['Dynamism'].mean(),\n",
        "    'Mobility': df['Mobility'].mean(),\n",
        "    'English': df['English'].mean()\n",
        "}\n",
        "df = df.fillna(fill_values)\n",
        "print(f'There are {df.isnull().sum().sum()} NANs')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohSRbTbT1ExU"
      },
      "source": [
        "### Features Remapping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "citizenship_mapping = {\n",
        "    'Pakistani': 'Non-European',\n",
        "    'Italian': 'European',\n",
        "    'Not Specified': 'Non-European',\n",
        "    'Moroccan': 'Non-European',\n",
        "    'Iranian': 'Non-European',\n",
        "    'Albanian': 'European',\n",
        "    'Indiana': 'Non-European',\n",
        "    'Colombian': 'Non-European',\n",
        "    'Ethiopian': 'Non-European',\n",
        "    'Romanian': 'European',\n",
        "    'Vltava': 'European',\n",
        "    'Lebanese': 'Non-European',\n",
        "    'Spanish': 'European',\n",
        "    'Egyptian': 'Non-European',\n",
        "    'Russian': 'European',\n",
        "    'Tunisian': 'Non-European',\n",
        "    'Turkish': 'European',\n",
        "    'Chinese': 'Non-European',\n",
        "    'Uzbek': 'Non-European',\n",
        "    'Brazilian': 'Non-European',\n",
        "    'Cameroonian': 'Non-European',\n",
        "    'Sudanese': 'Non-European',\n",
        "    'Algerian': 'Non-European',\n",
        "    'Croatian': 'European',\n",
        "    'Polish': 'European',\n",
        "    'Indonesian': 'Non-European',\n",
        "    'San Marino': 'European',\n",
        "    'Argentina': 'Non-European',\n",
        "    'Azerbaijan': 'Non-European',\n",
        "    'Portuguese': 'European',\n",
        "    'Serbian': 'European',\n",
        "    'French': 'European',\n",
        "    'Swiss': 'European',\n",
        "    'German': 'European',\n",
        "    'Peruvian': 'Non-European',\n",
        "    'British': 'European',\n",
        "    'Venezuelan': 'Non-European',\n",
        "    'Rwandan': 'Non-European',\n",
        "    'Costa Rican': 'Non-European',\n",
        "    'South Korean': 'Non-European',\n",
        "    'Ukraine': 'European',\n",
        "    'Macedonian': 'European',\n",
        "    'Nigerian': 'Non-European',\n",
        "    'American': 'Non-European',\n",
        "    'Kenyan': 'Non-European',\n",
        "    'Emirati': 'Non-European',\n",
        "    'Ecuadorian': 'Non-European',\n",
        "    'Ivorian': 'Non-European',\n",
        "    'Mexican': 'Non-European',\n",
        "    'Chilean': 'Non-European',\n",
        "    'Japanese': 'Non-European',\n",
        "    'Syrian': 'Non-European',\n",
        "    'Bangladeshis': 'Non-European',\n",
        "    'Greek': 'European',\n",
        "    'Israeli': 'Non-European',\n",
        "    'Omani': 'Non-European',\n",
        "    'South African': 'Non-European',\n",
        "    'Bolivian': 'Non-European',\n",
        "    'Filipina': 'Non-European',\n",
        "    'Sinhalese': 'Non-European',\n",
        "    'Palestinian (Palestinian Territories)': 'Non-European',\n",
        "    'Afghan': 'Non-European',\n",
        "    'Jordan': 'Non-European',\n",
        "    'Cuban': 'Non-European',\n",
        "    'Vietnamese': 'Non-European',\n",
        "    'Latvian': 'European',\n",
        "    'Libyan': 'Non-European',\n",
        "    'Bulgarian': 'European',\n",
        "    'Togolese': 'Non-European',\n",
        "    'Kazakh': 'Non-European',\n",
        "    'Austrian': 'European',\n",
        "    'Belarusian': 'European',\n",
        "    'Saudi': 'Non-European',\n",
        "    'Bosnian': 'European',\n",
        "    'Kyrgyz': 'Non-European',\n",
        "    'Tajik': 'Non-European',\n",
        "    'Dutch': 'European',\n",
        "    'Qatari': 'Non-European',\n",
        "    'Georgian': 'European',\n",
        "    'Canadian': 'Non-European',\n",
        "    'Australian': 'Non-European',\n",
        "    'Salvadoran': 'Non-European',\n",
        "    'Congolese': 'Non-European',\n",
        "    'Guatemalan': 'Non-European',\n",
        "    'Hungarian': 'European',\n",
        "    'Tanzanian': 'Non-European',\n",
        "    'Gabonese': 'Non-European',\n",
        "    'Angolan': 'Non-European',\n",
        "    'Maltese': 'European'\n",
        "}\n",
        "\n",
        "study_area_mapping = {\n",
        "    'Automation/Mechatronics Engineering': 'Engineering',\n",
        "    'computer engineering': 'Engineering',\n",
        "    'chemical engineering': 'Engineering',\n",
        "    'Legal': 'Law',\n",
        "    'Mechanical engineering': 'Engineering',\n",
        "    'Telecommunications Engineering': 'Engineering',\n",
        "    'Economic - Statistics': 'Economic',\n",
        "    'Psychology': 'Scientific Field',\n",
        "    'Materials Science and Engineering': 'Engineering',\n",
        "    'Other scientific subjects': 'Scientific Field',\n",
        "    'Biomedical Engineering': 'Engineering',\n",
        "    'electronic Engineering': 'Engineering',\n",
        "    'Information Engineering': 'Engineering',\n",
        "    'Aeronautical/Aerospace/Astronautics Engineering': 'Engineering',\n",
        "    'Energy and Nuclear Engineering': 'Engineering',\n",
        "    'Informatics': 'Informatics',\n",
        "    'Management Engineering': 'Engineering',\n",
        "    'Automotive Engineering': 'Engineering',\n",
        "    'industrial engineering': 'Engineering',\n",
        "    'Other': 'Other',\n",
        "    'Surveyor': 'NO COLLEGE',\n",
        "    'Civil/Civil and Environmental Engineering': 'Engineering',\n",
        "    'Electrical Engineering': 'Engineering',\n",
        "    'Scientific maturity': 'NO COLLEGE',\n",
        "    'Chemist - Pharmaceutical': 'Medical Field',\n",
        "    'Political-Social': 'Other Humanities Subjects',\n",
        "    'Other humanities subjects': 'Other Humanities Subjects',\n",
        "    'Geo-Biological': 'Scientific Field',\n",
        "    'Linguistics': 'Linguistics',\n",
        "    'Agriculture and veterinary': 'Scientific Field',\n",
        "    'Literary': 'Other Humanities Subjects',\n",
        "    'Humanistic high school diploma': 'NO COLLEGE',\n",
        "    'Accounting': 'NO COLLEGE',\n",
        "    'Communication Sciences': 'Other Humanities Subjects',\n",
        "    'Safety Engineering': 'Engineering',\n",
        "    'Architecture': 'Scientific Field',\n",
        "    'Mathematics': 'Scientific Field',\n",
        "    'construction Engineering': 'Engineering',\n",
        "    'Petroleum Engineering': 'Engineering',\n",
        "    'Naval Engineering': 'Engineering',\n",
        "    'Artistic': 'NO COLLEGE',\n",
        "    'Not Specified': 'Other',\n",
        "    'Mathematical-physical modeling for engineering': 'Engineering',\n",
        "    'Engineering for the environment and the territory': 'Engineering',\n",
        "    'Medical': 'Medical Field',\n",
        "    'Defense and Security': 'Other',\n",
        "    'Physical education': 'Other',\n",
        "    'Statistics': 'Scientific Field',\n",
        "    'Educational/training sciences': 'Other Humanities Subjects'\n",
        "\n",
        "}\n",
        "\n",
        "age_mapping = {\n",
        "    '< 20 years': 'Young',\n",
        "    '20 - 25 years': 'Young',\n",
        "    '26 - 30 years': 'Young',\n",
        "    '31 - 35 years': 'Young',\n",
        "    '36 - 40 years': 'Senior',\n",
        "    '40 - 45 years': 'Senior',\n",
        "    '> 45 years': 'Senior'\n",
        "}\n",
        "\n",
        "df['Citizenship'] = df['Citizenship'].replace(citizenship_mapping)\n",
        "df['Age Range'] = df['Age Range'].replace(age_mapping)\n",
        "df['Study area'] = df['Study area'].replace(study_area_mapping)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NlOnBSVF1ExV"
      },
      "source": [
        "### Target Column"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRjVe10r1ExV",
        "outputId": "88790b0c-536a-41d4-bbb2-1341787a8e9d"
      },
      "outputs": [],
      "source": [
        "df['Status'] = np.where(\n",
        "    (df['Candidate State'] == 'Hired') | \n",
        "    (df['Candidate State'] == 'Economic proposal') | \n",
        "    (df['event_feedback'] == 'OK (live)') | \n",
        "    (df['event_feedback'] == 'OK (waiting for departure)') | \n",
        "    (df['event_feedback'] == 'OK (hired)') | \n",
        "    (df['Candidate State'] == 'QM'), 'Valid', 'Non Valid')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4GkzsY6s1ExW"
      },
      "source": [
        "### Categorical columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gOBlkj5x1ExW"
      },
      "outputs": [],
      "source": [
        "encoding_mappings = {}\n",
        "\n",
        "categorical_columns = [\n",
        "    'Status', 'Age Range', 'Citizenship', 'Sex',\n",
        "    'Protected category', 'Study area', 'Study Title',\n",
        "    'Years Experience', 'Sector', 'Job Family Hiring',\n",
        "    'Job Title Hiring', 'Overall',\n",
        "    'Minimum Ral', 'Ral Maximum', 'Study Level',\n",
        "    'Current Ral', 'Expected Ral'\n",
        "]\n",
        "\n",
        "custom_orders = {\n",
        "    'Age Range': ['< 20 years', '20 - 25 years', '26 - 30 years',\n",
        "                  '31 - 35 years', '36 - 40 years', '40 - 45 years', '> 45 years'],\n",
        "    'Years Experience': ['[0]', '[0-1]', '[1-3]', '[3-5]', '[5-7]', '[7-10]', '[+10]'],\n",
        "}\n",
        "\n",
        "for col in categorical_columns:\n",
        "    if col in custom_orders:\n",
        "        df[f\"{col}_encoded\"] = pd.Categorical(df[col], categories=custom_orders[col], ordered=True).codes\n",
        "        encoding_mappings[col] = {cat: i for i, cat in enumerate(custom_orders[col])}\n",
        "    else:\n",
        "        encoder = LabelEncoder()\n",
        "        df[f\"{col}_encoded\"] = encoder.fit_transform(df[col].astype(str))\n",
        "        encoding_mappings[col] = dict(zip(encoder.classes_, encoder.transform(encoder.classes_)))\n",
        "\n",
        "df = df.drop(columns=categorical_columns)\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EIYO8Uhi1ExW"
      },
      "source": [
        "### Visualize Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "lookups = ['Citizenship', 'Age Range', 'Sex', 'Protected category', 'Study area', 'Study Title', 'Years Experience']\n",
        "for lookup in lookups:\n",
        "    mapping = {v: k for k, v in encoding_mappings[lookup].items()}\n",
        "\n",
        "    distrib = Counter(df[f\"{lookup}_encoded\"])\n",
        "    distrib_df = pd.DataFrame(distrib.items(), columns=[f\"{lookup}_encoded\", 'Count'])\n",
        "    distrib_df[lookup] = distrib_df[f\"{lookup}_encoded\"].map(mapping)\n",
        "    distrib_df.head(20).plot(x=lookup, y='Count', kind='bar', legend=False)\n",
        "    plt.title(lookup)\n",
        "    plt.xticks(rotation=45)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Correlation Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sns.heatmap(df.corr(), annot=True, cmap='coolwarm', center=0, linewidths=.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Visualize Percentage of Hired inside each class"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sensitive = ['Sex_encoded', 'Age Range_encoded', 'Citizenship_encoded', 'Protected Category_encoded']\n",
        "for feature in sensitive:\n",
        "    percentage = df.groupby(feature)['STATUS'].mean().mul(100).round(2)\n",
        "    for category, perc in percentage.items():\n",
        "        print(f\"Percentage of elements where {feature} is {category} and STATUS is HIRED: {percentage:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NM7TxgLU1ExW"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Dataset Preparation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8PH7esVa1ExW"
      },
      "outputs": [],
      "source": [
        "df = shuffle(df, random_state=random_seed)\n",
        "X_full = df.drop(columns=['STATUS'])\n",
        "y = df['STATUS']\n",
        "X_train_full, X_test_full, y_train_full, y_test_full = train_test_split(X_full, y, test_size=0.2, random_state=random_seed, stratify=y)\n",
        "\n",
        "X = df.drop(columns=['STATUS', 'sex'])\n",
        "y = df['STATUS']\n",
        "s = df['sex']\n",
        "X_train, X_test, y_train, y_test, s_train, s_test = train_test_split(X, y, s, test_size=0.2, random_state=random_seed, stratify=y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_df = X_train.copy()\n",
        "train_df['target'] = y_train.values\n",
        "train_df['sex'] = s_train.values\n",
        "\n",
        "test_df = X_test.copy()\n",
        "test_df['target'] = y_test.values\n",
        "test_df['sex'] = s_test.values\n",
        "\n",
        "train_ds = StandardDataset(\n",
        "    train_df,\n",
        "    label_name='target',\n",
        "    favorable_classes=[1],\n",
        "    protected_attribute_names=['sex'],\n",
        "    privileged_classes=[[1]]\n",
        ")\n",
        "\n",
        "test_ds = StandardDataset(\n",
        "    test_df,\n",
        "    label_name='target',\n",
        "    favorable_classes=[1],\n",
        "    protected_attribute_names=['sex'],\n",
        "    privileged_classes=[[1]]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "lfr = LFR(unprivileged_groups=[{'sex': 0}], privileged_groups=[{'sex': 1}], k=10, Ax=5, Ay=5, Az=10, max_iter=50, verbose=1)\n",
        "\n",
        "lfr = lfr.fit(train_ds)\n",
        "X_train_lfr = lfr.transform(train_ds)\n",
        "X_train_lfr_df = pd.DataFrame(X_train_lfr.features, columns=train_ds.feature_names)\n",
        "\n",
        "\n",
        "clf = LogisticRegression(solver='liblinear')\n",
        "clf.fit(X_train_lfr_df, y_train)\n",
        "preds_lfr = clf.predict(pd.DataFrame(lfr.transform(test_ds).features, columns=train_ds.feature_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "cr = CorrelationRemover(sensitive_feature_ids=[train_ds.feature_names.index('sex')])\n",
        "\n",
        "X_train_cr = cr.fit_transform(X_train)\n",
        "X_train_cr_df = pd.DataFrame(X_train_cr.features, columns=train_ds.feature_names)\n",
        "\n",
        "X_test_cr  = cr.transform(X_test)\n",
        "X_test_cr_df = pd.DataFrame(X_test_cr.features, columns=train_ds.feature_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "gfc = GerryFairClassifier(\n",
        "    unprivileged_groups=[{'sex': 0}],\n",
        "    privileged_groups=[{'sex': 1}],\n",
        "    estimator=LogisticRegression(solver='liblinear'),\n",
        "    constraints='demographic_parity'\n",
        ")\n",
        "gfc.fit(train_ds)\n",
        "pred_gfc = gfc.predict(test_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pr = PrejudiceRemover(\n",
        "    sensitive_attr='sex',\n",
        "    eta=25.0\n",
        ")\n",
        "pr.fit(train_ds)\n",
        "pred_pr = pr.predict(test_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mfc = MetaFairClassifier(\n",
        "    unprivileged_groups=[{'sex': 0}],\n",
        "    privileged_groups=[{'sex': 1}],\n",
        "    sensitive_attr='sex',\n",
        "    tau=0.8\n",
        ")\n",
        "mfc.fit(train_ds)\n",
        "pred_mfc = mfc.predict(test_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "eop = EqOddsPostprocessing(\n",
        "    unprivileged_groups=[{'sex': 0}],\n",
        "    privileged_groups=[{'sex': 1}]\n",
        ")\n",
        "eop = eop.fit(train_ds, gfc.predict(train_ds))\n",
        "pred_eop = eop.predict(test_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "roc = RejectOptionClassification(\n",
        "    unprivileged_groups=[{'sex': 0}],\n",
        "    privileged_groups=[{'sex': 1}],\n",
        "    low_class_thresh=0.01,\n",
        "    high_class_thresh=0.99,\n",
        "    num_class_thresh=100,\n",
        "    metric_name='Average odds difference'\n",
        ")\n",
        "roc = roc.fit(train_ds, gfc.predict(train_ds))\n",
        "pred_roc = roc.predict(test_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_fairness_metrics(y_true, y_pred, sensitive_features, label=None):\n",
        "    mf = MetricFrame(\n",
        "        metrics={\n",
        "            'selection_rate': selection_rate,\n",
        "            'dp_diff': demographic_parity_difference,\n",
        "            'eo_diff': equalized_odds_difference,\n",
        "            'fpr': false_positive_rate,\n",
        "            'fnr': false_negative_rate,\n",
        "            'count': count\n",
        "        },\n",
        "        y_true=y_true,\n",
        "        y_pred=y_pred,\n",
        "        sensitive_features=sensitive_features\n",
        "    )\n",
        "    if label:\n",
        "        print(f\"=== {label} ===\")\n",
        "    print(mf.by_group)\n",
        "    print(\"Overall:\", mf.overall, \"\\n\")\n",
        "    return mf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Pre-Processing\n",
        "compute_fairness_metrics(y_test, preds_lfr, s_test, label=\"LFR + LogisticRegression\")\n",
        "\n",
        "# In-processing\n",
        "compute_fairness_metrics(y_test, pred_gfc.ravel(), s_test, label=\"GerryFairClassifier\")\n",
        "compute_fairness_metrics(y_test, pred_pr.ravel(), s_test, label=\"PrejudiceRemover\")\n",
        "compute_fairness_metrics(y_test, pred_mfc.ravel(), s_test, label=\"MetaFairClassifier\")\n",
        "\n",
        "# Post-processing\n",
        "compute_fairness_metrics(y_test, pred_eop.ravel(), s_test, label=\"EqOddsPostprocessing\")\n",
        "compute_fairness_metrics(y_test, pred_roc.ravel(), s_test, label=\"RejectOptionClassification\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mXTBN9yJ1ExW"
      },
      "source": [
        "### Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7neYICfm1ExW"
      },
      "outputs": [],
      "source": [
        "def create_model(seed):\n",
        "    tf.random.set_seed(seed)\n",
        "    model = Sequential()\n",
        "    model.add(Dense(128, input_dim=22, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "models = {\n",
        "    'Linear Regression': LinearRegression(),\n",
        "    'Decision Tree': DecisionTreeClassifier(),\n",
        "    'Naive Bayes': GaussianNB(),\n",
        "    'XGBoost': XGBClassifier(),\n",
        "    'KNN': KNeighborsClassifier(),\n",
        "    'Neural Network': create_model(random_seed)\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "bSyQkZB91ExX",
        "outputId": "166c5665-77b9-4e4b-d2b7-e20eef41a9d7"
      },
      "outputs": [],
      "source": [
        "metrics = []\n",
        "predictions = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    if name in ['Linear Regression', 'Decision Tree', 'Naive Bayes', 'XGBoost', 'KNN']:\n",
        "        model.fit(X_train_full, y_train_full)\n",
        "    elif name in ['Neural Network']:\n",
        "        model.fit(X_train_full, y_train_full, epochs=15, batch_size=64, validation_split=0.2)\n",
        "    else:\n",
        "        print(\"Error in Models!\"); break\n",
        "\n",
        "    y_pred = model.predict(X_test_full)\n",
        "\n",
        "    if name in ['Linear Regression', 'XGBoost', 'Neural Network']:\n",
        "        y_pred = (y_pred > 0.5).astype(int)\n",
        "\n",
        "    accuracy = round(accuracy_score(y_test_full, y_pred), 3)\n",
        "    precision = round(precision_score(y_test_full, y_pred), 3)\n",
        "    recall = round(recall_score(y_test_full, y_pred), 3)\n",
        "    f1 = round(f1_score(y_test_full, y_pred), 3)\n",
        "    roc_auc = round(roc_auc_score(y_test_full, y_pred), 3)\n",
        "\n",
        "    metrics.append({\n",
        "        'Model': name,\n",
        "        'Accuracy': accuracy,\n",
        "        'Precision': precision,\n",
        "        'Recall': recall,\n",
        "        'F1-score': f1,\n",
        "        'ROC AUC': roc_auc\n",
        "    })\n",
        "    predictions[name] = y_pred\n",
        "\n",
        "metrics = pd.DataFrame(metrics)\n",
        "predictions_df = pd.DataFrame({\n",
        "    'Linear Regression' : predictions['Linear Regression'],\n",
        "    'Decision Tree' : predictions['Decision Tree'],\n",
        "    'Naive Bayes' : predictions['Naive Bayes'],\n",
        "    'XGBoost' : predictions['XGBoost'],\n",
        "    'kNN' : predictions['KNN'],\n",
        "    'Neural Network' : predictions['Neural Network']\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GybD2fNN1Exa"
      },
      "source": [
        "## Fairness Metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Ws-DQHm1Exa"
      },
      "source": [
        "#### **3.1 Demographic Parity**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qCdj5tff1Exb"
      },
      "outputs": [],
      "source": [
        "sensitive_features = [' Sex_encoded', ' Age Range_encoded', ' Citizenship_encoded', ' Protected category_encoded']\n",
        "non_sensitive_features = ['Technical Skills', 'Comunication', 'Maturity', 'Dynamism', 'Mobility',\n",
        "       'English', ' Study area_encoded', ' Study Title_encoded', ' Years Experience_encoded', ' Sector_encoded', ' Job Family Hiring_encoded',\n",
        "       ' Job Title Hiring_encoded', ' Overall_encoded', ' Years Experience.1_encoded',' Minimum Ral_encoded', ' Ral Maximum_encoded',\n",
        "       ' Study Level_encoded', 'Current Ral_encoded', 'Expected Ral_encoded']\n",
        "models_list = [model for model in models]\n",
        "tolerance = 0.15\n",
        "significance_level = 0.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QzubVOQ61Exb"
      },
      "outputs": [],
      "source": [
        "def calculate_demographic_parity(predictions, sensitive_attribute, name, significance_level, tolerance, activate_check=False):\n",
        "\n",
        "    df = pd.DataFrame({\n",
        "        'predictions': predictions,\n",
        "        'sensitive_attribute': sensitive_attribute\n",
        "    })\n",
        "    prop = df.groupby('sensitive_attribute')['predictions'].mean()\n",
        "    \n",
        "    if activate_check:\n",
        "        print(f\"===\\n{name}\\n{prop}\")\n",
        "\n",
        "    if prop.shape[0] == 2:\n",
        "        return 'T' if (prop.max() - prop.min()) <= tolerance else False\n",
        "    else:\n",
        "        contingency_table = pd.crosstab(df['predictions'], df['sensitive_attribute'])\n",
        "        chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
        "\n",
        "        if activate_check and (expected < 5).any():\n",
        "            print(f\"Sparse contingency for {name}\")\n",
        "                \n",
        "        return 'T' if p > significance_level else False\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 862
        },
        "id": "dYqVcPet1Exb",
        "outputId": "6422f8a3-7d22-4ab2-d8b8-867596fc79dc"
      },
      "outputs": [],
      "source": [
        "table = []\n",
        "for model in models:\n",
        "    row = []\n",
        "    for sensitive_feature in sensitive_features:\n",
        "        result = calculate_demographic_parity(predictions[model], X_test_full[sensitive_feature], sensitive_feature, significance_level, tolerance, activate_check=True)\n",
        "        row.append(result)\n",
        "    table.append(row)\n",
        "sf_df = pd.DataFrame(table, index = models_list, columns=sensitive_features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PJ1zcOEM1Exb"
      },
      "source": [
        "#### **3.2 Equalized odds**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wXbOhlKv1Exb"
      },
      "outputs": [],
      "source": [
        "def calculate_equalized_odds(predictions, true_labels, sensitive_attribute, name, tolerance, activate_check=False):\n",
        "    df = pd.DataFrame({\n",
        "        'predictions': predictions,\n",
        "        'true_labels': true_labels,\n",
        "        'sensitive_attribute': sensitive_attribute\n",
        "    })\n",
        "    tprs, fprs = [], []\n",
        "    for _, group_df in df.groupby('sens'):\n",
        "        tn, fp, fn, tp = confusion_matrix(group_df['true_labels'], group_df['predictions'], labels=[0, 1]).ravel()\n",
        "        tprs.append(tp / (tp + fn) if tp + fn != 0 else 0)\n",
        "        fprs.append(fp / (fp + tn) if fp + tn != 0 else 0)\n",
        "\n",
        "    max_tpr_diff = max(tprs) - min(tprs)\n",
        "    max_fpr_diff = max(fprs) - min(fprs)\n",
        "\n",
        "    if activate_check:\n",
        "            print(f\"===\\n{name}\\nMax FPR diff: {max_fpr_diff}\\nMax TPR diff: {max_tpr_diff}\")\n",
        "\n",
        "    return 'T' if (max_tpr_diff <= 2 * tolerance and max_fpr_diff <= 2 * tolerance) else False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        },
        "id": "9KSoLzk21Exb",
        "outputId": "6f420612-90e8-4537-f6fb-43add15ddac2"
      },
      "outputs": [],
      "source": [
        "table = []\n",
        "for model in models:\n",
        "    row = []\n",
        "    for sensitive_feature in sensitive_features:\n",
        "        result = calculate_equalized_odds(predictions[model], y_test_full, X_test_full[sensitive_feature], sensitive_feature, tolerance, activate_check=False)\n",
        "        row.append(result)\n",
        "    table.append(row)\n",
        "sf_df = pd.DataFrame(table, index = models_list, columns=sensitive_features)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
